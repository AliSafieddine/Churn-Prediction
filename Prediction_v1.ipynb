{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd82ba2",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1c2a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "%matplotlib inline\n",
    "import pandas as pd \n",
    "from tabulate import tabulate\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bbd1f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('train_month_3_with_target.csv')\n",
    "train2 = pd.read_csv('train_month_2.csv')\n",
    "train3 = pd.read_csv('train_month_1.csv')\n",
    "test1 = pd.read_csv('test_month_3.csv')\n",
    "test2 = pd.read_csv('test_month_2.csv')\n",
    "test3 = pd.read_csv('test_month_1.csv')\n",
    "\n",
    "copy_df = pd.read_csv('train_month_3_with_target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef77515",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aea096",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a986ebc",
   "metadata": {},
   "source": [
    "## Dataset Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d76ed72b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63697 entries, 0 to 63696\n",
      "Data columns (total 40 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   client_id                          63697 non-null  object \n",
      " 1   homebanking_active                 63697 non-null  int64  \n",
      " 2   has_homebanking                    63697 non-null  int64  \n",
      " 3   has_insurance_21                   63697 non-null  int64  \n",
      " 4   has_insurance_23                   63697 non-null  int64  \n",
      " 5   has_life_insurance_fixed_cap       63697 non-null  int64  \n",
      " 6   has_life_insurance_decreasing_cap  63697 non-null  int64  \n",
      " 7   has_fire_car_other_insurance       63697 non-null  int64  \n",
      " 8   has_personal_loan                  63697 non-null  int64  \n",
      " 9   has_mortgage_loan                  63697 non-null  int64  \n",
      " 10  has_current_account                63697 non-null  int64  \n",
      " 11  has_pension_saving                 63697 non-null  int64  \n",
      " 12  has_savings_account                63697 non-null  int64  \n",
      " 13  has_savings_account_starter        63697 non-null  int64  \n",
      " 14  has_current_account_starter        63697 non-null  int64  \n",
      " 15  bal_insurance_21                   63697 non-null  int64  \n",
      " 16  bal_insurance_23                   63697 non-null  int64  \n",
      " 17  cap_life_insurance_fixed_cap       63697 non-null  int64  \n",
      " 18  cap_life_insurance_decreasing_cap  63697 non-null  int64  \n",
      " 19  prem_fire_car_other_insurance      63697 non-null  int64  \n",
      " 20  bal_personal_loan                  63697 non-null  int64  \n",
      " 21  bal_mortgage_loan                  63697 non-null  int64  \n",
      " 22  bal_current_account                63697 non-null  int64  \n",
      " 23  bal_pension_saving                 63697 non-null  int64  \n",
      " 24  bal_savings_account                63697 non-null  int64  \n",
      " 25  bal_savings_account_starter        63697 non-null  int64  \n",
      " 26  bal_current_account_starter        63697 non-null  int64  \n",
      " 27  visits_distinct_so                 63697 non-null  float64\n",
      " 28  visits_distinct_so_areas           63697 non-null  float64\n",
      " 29  customer_since_all                 63463 non-null  object \n",
      " 30  customer_since_bank                63448 non-null  object \n",
      " 31  customer_gender                    63697 non-null  int64  \n",
      " 32  customer_birth_date                63697 non-null  object \n",
      " 33  customer_postal_code               63697 non-null  int64  \n",
      " 34  customer_occupation_code           61695 non-null  float64\n",
      " 35  customer_self_employed             63697 non-null  int64  \n",
      " 36  customer_education                 16572 non-null  float64\n",
      " 37  customer_children                  40333 non-null  object \n",
      " 38  customer_relationship              48798 non-null  object \n",
      " 39  target                             63697 non-null  int64  \n",
      "dtypes: float64(4), int64(30), object(6)\n",
      "memory usage: 19.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#train1.info()\n",
    "train1.describe()\n",
    "train1.isna().any()\n",
    "train1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "617db495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continious variables are: ['bal_insurance_21', 'bal_insurance_23', 'cap_life_insurance_fixed_cap', 'cap_life_insurance_decreasing_cap', 'prem_fire_car_other_insurance', 'bal_personal_loan', 'bal_mortgage_loan', 'bal_current_account', 'bal_pension_saving', 'bal_savings_account', 'bal_savings_account_starter', 'bal_current_account_starter', 'customer_since_all', 'customer_since_bank', 'customer_birth_date', 'customer_postal_code']\n",
      "------------------\n",
      "Categorical variables are: ['homebanking_active', 'has_homebanking', 'has_insurance_21', 'has_insurance_23', 'has_life_insurance_fixed_cap', 'has_life_insurance_decreasing_cap', 'has_fire_car_other_insurance', 'has_personal_loan', 'has_mortgage_loan', 'has_current_account', 'has_pension_saving', 'has_savings_account', 'has_savings_account_starter', 'has_current_account_starter', 'visits_distinct_so', 'visits_distinct_so_areas', 'customer_gender', 'customer_occupation_code', 'customer_self_employed', 'customer_education', 'customer_children', 'customer_relationship', 'target']\n"
     ]
    }
   ],
   "source": [
    "train1['customer_since_all'] = pd.to_datetime(train1['customer_since_all'])\n",
    "train1['customer_since_bank'] = pd.to_datetime(train1['customer_since_bank'])\n",
    "train1['customer_birth_date'] = pd.to_datetime(train1['customer_birth_date'])\n",
    "\n",
    "cat_vars = []\n",
    "cont_vars = []\n",
    "columns = list(train1.drop(columns = ['client_id']).columns)\n",
    "for i in columns:\n",
    "    if (len(train1.loc[:,i].unique()) >= 20):\n",
    "        cont_vars.append(i)\n",
    "    else:\n",
    "        cat_vars.append(i)\n",
    "        \n",
    "print('Continious variables are:',cont_vars)\n",
    "print('------------------')\n",
    "print('Categorical variables are:',cat_vars)\n",
    "# Here we have our list of categorical and continious variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1fe9a0",
   "metadata": {},
   "source": [
    "### Categorical features unique values - checking consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2757e8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homebanking_active [0 1]\n",
      "has_homebanking [0 1]\n",
      "has_insurance_21 [0 1]\n",
      "has_insurance_23 [0 1]\n",
      "has_life_insurance_fixed_cap [0 1]\n",
      "has_life_insurance_decreasing_cap [0 1]\n",
      "has_fire_car_other_insurance [1 0]\n",
      "has_personal_loan [0 1]\n",
      "has_mortgage_loan [0 1]\n",
      "has_current_account [1 0]\n",
      "has_pension_saving [0 1]\n",
      "has_savings_account [1 0]\n",
      "has_savings_account_starter [0 1]\n",
      "has_current_account_starter [0 1]\n",
      "visits_distinct_so [1. 2. 3. 4. 6. 5. 7.]\n",
      "visits_distinct_so_areas [1. 2. 3. 5. 4. 6.]\n",
      "customer_gender [1 2]\n",
      "customer_occupation_code [ 9. nan  7.  8.  4.  5.  0.  6.  3.  1.  2.]\n",
      "customer_self_employed [0 1]\n",
      "customer_education [ 0. nan  2.  1.  4.  3.  5.  6.]\n",
      "customer_children [nan 'mature' 'no' 'young' 'preschool' 'adolescent' 'grownup' 'onebaby'\n",
      " 'yes']\n",
      "customer_relationship [nan 'couple' 'single']\n",
      "target [0 1]\n"
     ]
    }
   ],
   "source": [
    "# To check we will print all unique values\n",
    "for col in cat_vars:\n",
    "    print(col,train1[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0bab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks good, should transform into categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e739ff40",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a9ca35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>missing values</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>customer_since_all</td>\n",
       "      <td>234</td>\n",
       "      <td>0.367364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>customer_since_bank</td>\n",
       "      <td>249</td>\n",
       "      <td>0.390913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>customer_occupation_code</td>\n",
       "      <td>2002</td>\n",
       "      <td>3.143005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>customer_relationship</td>\n",
       "      <td>14899</td>\n",
       "      <td>23.390427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>customer_children</td>\n",
       "      <td>23364</td>\n",
       "      <td>36.679906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>customer_education</td>\n",
       "      <td>47125</td>\n",
       "      <td>73.983076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    variable  missing values          %\n",
       "29        customer_since_all             234   0.367364\n",
       "30       customer_since_bank             249   0.390913\n",
       "34  customer_occupation_code            2002   3.143005\n",
       "38     customer_relationship           14899  23.390427\n",
       "37         customer_children           23364  36.679906\n",
       "36        customer_education           47125  73.983076"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = train1.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['variable', 'missing values']\n",
    "missing_df['%']=(missing_df['missing values'])/train1.shape[0]*100\n",
    "missing_df = missing_df[missing_df['missing values'] >0].sort_values('%')\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eba673ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>missing values</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>customer_since_all</td>\n",
       "      <td>234</td>\n",
       "      <td>0.367364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>customer_since_bank</td>\n",
       "      <td>249</td>\n",
       "      <td>0.390913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>customer_occupation_code</td>\n",
       "      <td>2002</td>\n",
       "      <td>3.143005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>customer_relationship</td>\n",
       "      <td>14476</td>\n",
       "      <td>22.726345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>customer_children</td>\n",
       "      <td>23065</td>\n",
       "      <td>36.210497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>customer_education</td>\n",
       "      <td>47125</td>\n",
       "      <td>73.983076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    variable  missing values          %\n",
       "29        customer_since_all             234   0.367364\n",
       "30       customer_since_bank             249   0.390913\n",
       "34  customer_occupation_code            2002   3.143005\n",
       "38     customer_relationship           14476  22.726345\n",
       "37         customer_children           23065  36.210497\n",
       "36        customer_education           47125  73.983076"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = train2.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['variable', 'missing values']\n",
    "missing_df['%']=(missing_df['missing values'])/train1.shape[0]*100\n",
    "missing_df = missing_df[missing_df['missing values'] >0].sort_values('%')\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6645e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>missing values</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>customer_since_all</td>\n",
       "      <td>234</td>\n",
       "      <td>0.367364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>customer_since_bank</td>\n",
       "      <td>249</td>\n",
       "      <td>0.390913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>customer_occupation_code</td>\n",
       "      <td>2002</td>\n",
       "      <td>3.143005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>customer_relationship</td>\n",
       "      <td>14456</td>\n",
       "      <td>22.694946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>customer_children</td>\n",
       "      <td>23056</td>\n",
       "      <td>36.196367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>customer_education</td>\n",
       "      <td>47125</td>\n",
       "      <td>73.983076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    variable  missing values          %\n",
       "29        customer_since_all             234   0.367364\n",
       "30       customer_since_bank             249   0.390913\n",
       "34  customer_occupation_code            2002   3.143005\n",
       "38     customer_relationship           14456  22.694946\n",
       "37         customer_children           23056  36.196367\n",
       "36        customer_education           47125  73.983076"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = train3.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['variable', 'missing values']\n",
    "missing_df['%']=(missing_df['missing values'])/train1.shape[0]*100\n",
    "missing_df = missing_df[missing_df['missing values'] >0].sort_values('%')\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bfd3f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_since_all: 0\n",
      "customer_since_all: 0\n",
      "-----------------------------------------\n",
      "customer_since_bank: 0\n",
      "customer_since_bank: 0\n",
      "-----------------------------------------\n",
      "customer_occupation_code: 0\n",
      "customer_occupation_code: 0\n",
      "-----------------------------------------\n",
      "customer_relationship: 1000\n",
      "customer_relationship: 1015\n",
      "-----------------------------------------\n",
      "customer_children: 977\n",
      "customer_children: 984\n",
      "-----------------------------------------\n",
      "customer_education: 0\n",
      "customer_education: 0\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for x in ['customer_since_all','customer_since_bank','customer_occupation_code','customer_relationship',\n",
    "         'customer_children','customer_education']:\n",
    "    print(str(x) + \": \" + str(train2.loc[train1[x].isna(),x].value_counts().sum()))\n",
    "    print(str(x) + \": \" + str(train3.loc[train1[x].isna(),x].value_counts().sum()))\n",
    "    print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8686a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix customer relationship and customer children for training set\n",
    "train1['customer_children2'] = train2['customer_children']\n",
    "train1['customer_children3'] = train3['customer_children']\n",
    "\n",
    "train1.customer_children = np.where(train1.customer_children.isnull(), train1.customer_children2, train1.customer_children)\n",
    "train1.customer_children = np.where(train1.customer_children.isnull(), train1.customer_children3, train1.customer_children)\n",
    "\n",
    "\n",
    "train1['customer_relationship2'] = train2['customer_relationship']\n",
    "train1['customer_relationship3'] = train3['customer_relationship']\n",
    "\n",
    "train1.customer_relationship = np.where(train1.customer_relationship.isnull(), train1.customer_relationship2, train1.customer_relationship)\n",
    "train1.customer_relationship = np.where(train1.customer_relationship.isnull(), train1.customer_relationship3, train1.customer_relationship)\n",
    "\n",
    "train2['customer_children'] = train1['customer_children']\n",
    "train3['customer_children'] = train1['customer_children']\n",
    "\n",
    "train2['customer_relationship'] = train1['customer_relationship']\n",
    "train3['customer_relationship'] = train1['customer_relationship']\n",
    "\n",
    "train1 = train1.drop(columns = ['customer_relationship2','customer_relationship3',\n",
    "                                'customer_children2','customer_children3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "942d9d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_since_all: 0\n",
      "customer_since_all: 0\n",
      "-----------------------------------------\n",
      "customer_since_bank: 0\n",
      "customer_since_bank: 0\n",
      "-----------------------------------------\n",
      "customer_occupation_code: 0\n",
      "customer_occupation_code: 0\n",
      "-----------------------------------------\n",
      "customer_relationship: 0\n",
      "customer_relationship: 16\n",
      "-----------------------------------------\n",
      "customer_children: 0\n",
      "customer_children: 9\n",
      "-----------------------------------------\n",
      "customer_education: 0\n",
      "customer_education: 0\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for x in ['customer_since_all','customer_since_bank','customer_occupation_code','customer_relationship',\n",
    "         'customer_children','customer_education']:\n",
    "    print(str(x) + \": \" + str(test2.loc[test2[x].isna(),x].value_counts().sum()))\n",
    "    print(str(x) + \": \" + str(test3.loc[test2[x].isna(),x].value_counts().sum()))\n",
    "    print(\"-----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3dd0f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix customer relationship and customer children for training set\n",
    "test1['customer_children2'] = test2['customer_children']\n",
    "test1['customer_children3'] = test3['customer_children']\n",
    "\n",
    "test1.customer_children = np.where(test1.customer_children.isnull(), test1.customer_children2, test1.customer_children)\n",
    "test1.customer_children = np.where(test1.customer_children.isnull(), test1.customer_children3, test1.customer_children)\n",
    "\n",
    "\n",
    "test1['customer_relationship2'] = test2['customer_relationship']\n",
    "test1['customer_relationship3'] = test3['customer_relationship']\n",
    "\n",
    "test1.customer_relationship = np.where(test1.customer_relationship.isnull(), test1.customer_relationship2, test1.customer_relationship)\n",
    "test1.customer_relationship = np.where(test1.customer_relationship.isnull(), test1.customer_relationship3, test1.customer_relationship)\n",
    "\n",
    "test2['customer_children'] = test1['customer_children']\n",
    "test3['customer_children'] = test1['customer_children']\n",
    "\n",
    "test2['customer_relationship'] = test1['customer_relationship']\n",
    "test3['customer_relationship'] = test1['customer_relationship']\n",
    "\n",
    "test1 = test1.drop(columns = ['customer_relationship2','customer_relationship3',\n",
    "                                'customer_children2','customer_children3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "855f7cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how many churners are for the missing rows in customer_since_all & \n",
    "train1['target'].loc[(train1['customer_since_all'].isna()) & (train1['customer_since_bank'].isna())].sum()\n",
    "# We will drop columns with missing customer_since_all and customer_since_bank since they are very few churners among the NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edef495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[train1,train2,train3,test1,test2,test3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa6c8081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def drop_rows(x):\n",
    "    x.drop(x[x['customer_since_all'].isna()].index,inplace = True)\n",
    "    x.drop(x[x['customer_since_bank'].isna()].index,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2251b46d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in df_list:\n",
    "    drop_rows(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8ccb7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>missing values</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>customer_occupation_code</td>\n",
       "      <td>1980</td>\n",
       "      <td>3.120666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>customer_relationship</td>\n",
       "      <td>13832</td>\n",
       "      <td>21.800530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>customer_children</td>\n",
       "      <td>22305</td>\n",
       "      <td>35.154772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>customer_education</td>\n",
       "      <td>46944</td>\n",
       "      <td>73.988148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    variable  missing values          %\n",
       "34  customer_occupation_code            1980   3.120666\n",
       "38     customer_relationship           13832  21.800530\n",
       "37         customer_children           22305  35.154772\n",
       "36        customer_education           46944  73.988148"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = train1.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['variable', 'missing values']\n",
    "missing_df['%']=(missing_df['missing values'])/train1.shape[0]*100\n",
    "missing_df = missing_df[missing_df['missing values'] >0].sort_values('%')\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84bce05",
   "metadata": {},
   "source": [
    "Before we do anything with any of the columns with remainder of the missing values, we will select features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6bb879",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### hide temp explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d3c222f",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.countplot(x='customer_education',data=train1,hue='target',palette=\"coolwarm_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4ff69ab",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for x in range(0,10):\n",
    "#     print(f'job_code {x}', len(train1.loc[(train1['customer_occupation_code']==x)]))\n",
    "    \n",
    "# sns.histplot(x='customer_occupation_code',data=train1,hue='target',palette=\"coolwarm_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "914d325b",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sns.histplot(x='customer_occupation_code',data=train1,hue='target',palette=\"coolwarm_r\",multiple = \"fill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1415886c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# a = len(train1.loc[(train1['customer_relationship']=='couple') & (train1['target']== 0)])+len(train1.loc[(train1['customer_relationship']=='couple') & (train1['target']== 1)]) \n",
    "\n",
    "# b = len(train1.loc[(train1['customer_relationship']=='single') & (train1['target']== 0)])+ len(train1.loc[(train1['customer_relationship']=='single') & (train1['target']== 1)]) \n",
    "# table=[['Relationship','0','1'],\n",
    "#         [str(len(train1.loc[(train1['customer_relationship']=='couple')])) + ' Couple',round(len(train1.loc[(train1['customer_relationship']=='couple') & (train1['target']== 0)])/a,3 ),round(len(train1.loc[(train1['customer_relationship']=='couple') & (train1['target']== 1)])/a,3) ],\n",
    "#         [str(len(train1.loc[(train1['customer_relationship']=='single')])) + ' Single',round(len(train1.loc[(train1['customer_relationship']=='single') & (train1['target']== 0)])/b,3) ,round(len(train1.loc[(train1['customer_relationship']=='single') & (train1['target']== 1)])/b,3) ]]\n",
    "# print(tabulate(table, headers='firstrow'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81c122c1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# rep = {'mature':1,'no':0, 'young':1,'preschool':1,'adolescent':1,'grownup':1,'onebaby':1\n",
    "#  ,'yes':1}\n",
    "# train1['customer_children']= train1['customer_children'].replace(rep) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35b35f5e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# c = len(train1.loc[(train1['customer_children']==0) & (train1['target']== 0)])+len(train1.loc[(train1['customer_children']==0) & (train1['target']== 1)]) \n",
    "\n",
    "# d = len(train1.loc[(train1['customer_children']==1) & (train1['target']== 0)])+ len(train1.loc[(train1['customer_children']==1) & (train1['target']== 1)]) \n",
    "# table=[['Children','0','1'],\n",
    "#         [str(len(train1.loc[(train1['customer_children']==0)])) + ' Without kids',round(len(train1.loc[(train1['customer_children']==0) & (train1['target']== 0)])/c,2 ),round(len(train1.loc[(train1['customer_children']==0) & (train1['target']== 1)])/c,2) ],\n",
    "#         [str(len(train1.loc[(train1['customer_children']==1)])) + ' With kids',round(len(train1.loc[(train1['customer_children']==1) & (train1['target']== 0)])/d,2) ,round(len(train1.loc[(train1['customer_children']==1) & (train1['target']== 1)])/d,2) ]]\n",
    "# print(tabulate(table, headers='firstrow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a888859c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train1['customer_children'] = pd.Categorical(train1['customer_children'])\n",
    "# sns.histplot(x='customer_children',data=train1,hue='target',palette=\"coolwarm_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60385624",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot = sns.histplot(x='customer_children',data=train1,hue='target',palette=\"coolwarm_r\",multiple = \"fill\")\n",
    "# plot.set(ylim=(0,0.06))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae993c17",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# thjis var seems useful what do we do about missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42364997",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train1_test = train1.copy()\n",
    "# # train1_test['customer_children'].isna()\n",
    "# train1_test['customer_children'] = pd.to_numeric(train1_test['customer_children'])\n",
    "# train1_test.loc[train1_test['customer_children'].isna(),'customer_children'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fe44c66",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train1_test['customer_children'].replace({0:'no children',1:'children',2:'missing'})\n",
    "# train1_test['customer_children'] = pd.Categorical(train1_test['customer_children'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bf24883",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot = sns.histplot(x='customer_children',data=train1_test,hue='target',palette=\"coolwarm_r\",multiple = \"fill\")\n",
    "# plot.set(ylim=(0,0.06))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e700dc",
   "metadata": {},
   "source": [
    "## Create date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b8a4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def striptime(x):\n",
    "    x['customer_since_all'] = pd.to_datetime(x['customer_since_all'])\n",
    "    x['customer_since_bank'] = pd.to_datetime(x['customer_since_bank'])\n",
    "    x['customer_birth_date'] = pd.to_datetime(x['customer_birth_date'])\n",
    "    x['Birth_year'] = x['customer_birth_date'].dt.strftime('%Y').astype(str).astype(int)\n",
    "    x['Year_since_all'] = x['customer_since_all'].dt.strftime('%Y').astype(str).astype(int)\n",
    "    x['Year_since_bank'] = x['customer_since_bank'].dt.strftime('%Y').astype(str).astype(int)\n",
    "    x.drop(['customer_since_all','customer_since_bank','customer_birth_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4008928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def drop_col(x):\n",
    "#     x.drop(['customer_children','customer_relationship','customer_occupation_code',\n",
    "#             'customer_education',],axis=1, inplace=True) \n",
    "#     x.dropna(axis=0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6974559",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in df_list:\n",
    "    x = striptime(x)\n",
    "#     print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f2a7a9",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26791b7f",
   "metadata": {},
   "source": [
    "### Create Age variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06425af",
   "metadata": {},
   "source": [
    "First, let's extract the customer's Age and drop Birth_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9f2ae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_age(x):\n",
    "    x['Age'] = x['Birth_year'].apply(lambda x: 2018 -x)\n",
    "for x in df_list:\n",
    "    client_age(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f17fb7b",
   "metadata": {},
   "source": [
    "- We could see if there is a significant (large) difference in say balance or savings as this could be an indicator that the client is about to churn. (can just be stored as a boolean). \n",
    "- can also compute a boolean regarding the change in some services that the client has. Say he dropped in insurrance 21 last month or smtg. also as a boolean "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad908be3",
   "metadata": {},
   "source": [
    "### Removing outliers based on Birth year/Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350ce41c",
   "metadata": {},
   "source": [
    "We have noticed some of the clients are born in the 80s. Therefore we will assign a threshhold of 100years for the client's age.  In addition, the client's birth year cannot greater than the year he started using the banks services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "adce357d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_out(x):\n",
    "    x.drop(x[x['Birth_year'] < 1919].index, inplace = True)\n",
    "    x.drop(x.loc[x['Birth_year'] > (x['Year_since_all'] | x['Year_since_bank'])].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab502e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "652c186a",
   "metadata": {},
   "source": [
    "Additionally, customers aged 18 years old cannot own mature children or grownups. Hence they will be considered as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38c0b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_out2(x):\n",
    "    x.drop(x.loc[(x['customer_children'] ==\"preschool\") & (x['Age'] <21  )].index, inplace=True)\n",
    "    x.drop(x.loc[(x['customer_children'] ==\"young\") & (x['Age'] <28  )].index, inplace=True)\n",
    "    x.drop(x.loc[(x['customer_children'] ==\"adolescent\") & (x['Age'] <32  )].index, inplace=True)\n",
    "    x.drop(x.loc[(x['customer_children'] ==\"grownup\") & (x['Age'] <36  )].index, inplace=True)\n",
    "    x.drop(x.loc[(x['customer_children'] ==\"mature\") & (x['Age'] <42 )].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89d22000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in df_list:\n",
    "    remove_out(x)\n",
    "    remove_out2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaba34b",
   "metadata": {},
   "source": [
    "### Create client since variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36b150a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_since(x):\n",
    "    x['Year_since_all'] = x['Year_since_all'].apply(lambda x: 2018 -x)\n",
    "    x['Year_since_bank'] = x['Year_since_bank'].apply(lambda x: 2018 -x)\n",
    "    \n",
    "for x in df_list:\n",
    "    client_since(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b67e9",
   "metadata": {},
   "source": [
    "### Create difference variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67367856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a new column in the dataset with a boolean regarding if the values between the 3 columns are the same. \n",
    "\n",
    "def change(orig1,orig2,orig3, cols_bool,cols_cont,key ='client_id'):\n",
    "    columns= [key] + cols_bool + cols_cont\n",
    "    merged_1 = pd.merge(orig1,orig2[columns], how = 'left',on = key, suffixes=['','-1'])\n",
    "    merged = pd.merge(merged_1,orig3[columns], how = 'left',on = key, suffixes=['','-2'])\n",
    "    to_drop =[]\n",
    "    for var in cols_bool:\n",
    "        merged['ch_{}'.format(var)] = np.where((merged[var]==merged['{}-1'.format(var)])&(\n",
    "                                   merged[var] == merged['{}-2'.format(var)]),0,1)\n",
    "        merged['ch_{}'.format(var)] = pd.Categorical(merged['ch_{}'.format(var)])\n",
    "        merged[var] = pd.Categorical(merged[var])\n",
    "        to_drop+=['{}-1'.format(var),'{}-2'.format(var)]\n",
    "    for var in cols_cont:\n",
    "        merged['diff_mth1_{}'.format(var)] = -merged[var]+merged['{}-1'.format(var)]\n",
    "        merged['diff_mth2_{}'.format(var)] = -merged[var]+merged['{}-2'.format(var)]  \n",
    "        to_drop+=['{}-1'.format(var),'{}-2'.format(var)]\n",
    "    merged.drop(to_drop,axis=1,inplace=True)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbd0a8ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T14:59:59.376021Z",
     "start_time": "2022-04-06T14:59:59.127743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['client_id', 'homebanking_active', 'has_homebanking',\n",
       "       'has_insurance_21', 'has_insurance_23', 'has_life_insurance_fixed_cap',\n",
       "       'has_life_insurance_decreasing_cap', 'has_fire_car_other_insurance',\n",
       "       'has_personal_loan', 'has_mortgage_loan', 'has_current_account',\n",
       "       'has_pension_saving', 'has_savings_account',\n",
       "       'has_savings_account_starter', 'has_current_account_starter',\n",
       "       'bal_insurance_21', 'bal_insurance_23', 'cap_life_insurance_fixed_cap',\n",
       "       'cap_life_insurance_decreasing_cap', 'prem_fire_car_other_insurance',\n",
       "       'bal_personal_loan', 'bal_mortgage_loan', 'bal_current_account',\n",
       "       'bal_pension_saving', 'bal_savings_account',\n",
       "       'bal_savings_account_starter', 'bal_current_account_starter',\n",
       "       'visits_distinct_so', 'visits_distinct_so_areas', 'customer_gender',\n",
       "       'customer_postal_code', 'customer_occupation_code',\n",
       "       'customer_self_employed', 'customer_education', 'customer_children',\n",
       "       'customer_relationship', 'target', 'Birth_year', 'Year_since_all',\n",
       "       'Year_since_bank', 'Age', 'ch_homebanking_active', 'ch_has_homebanking',\n",
       "       'ch_has_insurance_21', 'ch_has_insurance_23',\n",
       "       'ch_has_life_insurance_fixed_cap',\n",
       "       'ch_has_life_insurance_decreasing_cap',\n",
       "       'ch_has_fire_car_other_insurance', 'ch_has_personal_loan',\n",
       "       'ch_has_mortgage_loan', 'ch_has_current_account',\n",
       "       'ch_has_pension_saving', 'ch_has_savings_account',\n",
       "       'ch_has_savings_account_starter', 'ch_has_current_account_starter',\n",
       "       'diff_mth1_bal_insurance_21', 'diff_mth2_bal_insurance_21',\n",
       "       'diff_mth1_bal_insurance_23', 'diff_mth2_bal_insurance_23',\n",
       "       'diff_mth1_bal_personal_loan', 'diff_mth2_bal_personal_loan',\n",
       "       'diff_mth1_bal_mortgage_loan', 'diff_mth2_bal_mortgage_loan',\n",
       "       'diff_mth1_bal_current_account', 'diff_mth2_bal_current_account',\n",
       "       'diff_mth1_bal_pension_saving', 'diff_mth2_bal_pension_saving',\n",
       "       'diff_mth1_bal_savings_account', 'diff_mth2_bal_savings_account',\n",
       "       'diff_mth1_bal_savings_account_starter',\n",
       "       'diff_mth2_bal_savings_account_starter',\n",
       "       'diff_mth1_bal_current_account_starter',\n",
       "       'diff_mth2_bal_current_account_starter',\n",
       "       'diff_mth1_cap_life_insurance_fixed_cap',\n",
       "       'diff_mth2_cap_life_insurance_fixed_cap',\n",
       "       'diff_mth1_cap_life_insurance_decreasing_cap',\n",
       "       'diff_mth2_cap_life_insurance_decreasing_cap'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new column regarding if there was a change in any var that starts w has_... in the last couple months\n",
    "# will be 1 if there was any change in the last 2 months 0 otherwise\n",
    "to_bool = ['homebanking_active', 'has_homebanking',\n",
    "       'has_insurance_21', 'has_insurance_23', 'has_life_insurance_fixed_cap',\n",
    "       'has_life_insurance_decreasing_cap', 'has_fire_car_other_insurance',\n",
    "       'has_personal_loan', 'has_mortgage_loan', 'has_current_account',\n",
    "       'has_pension_saving', 'has_savings_account',\n",
    "       'has_savings_account_starter', 'has_current_account_starter']\n",
    "to_diff_cont = ['bal_insurance_21', 'bal_insurance_23','bal_personal_loan', \n",
    "        'bal_mortgage_loan', 'bal_current_account',\n",
    "        'bal_pension_saving', 'bal_savings_account',\n",
    "        'bal_savings_account_starter', 'bal_current_account_starter',\n",
    "        'cap_life_insurance_fixed_cap','cap_life_insurance_decreasing_cap']\n",
    "train_s = change(train1,train2,train3, to_bool,to_diff_cont)\n",
    "train_s.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53a692ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_id                                      0\n",
       "homebanking_active                             0\n",
       "has_homebanking                                0\n",
       "has_insurance_21                               0\n",
       "has_insurance_23                               0\n",
       "                                              ..\n",
       "diff_mth2_bal_current_account_starter          0\n",
       "diff_mth1_cap_life_insurance_fixed_cap         0\n",
       "diff_mth2_cap_life_insurance_fixed_cap         0\n",
       "diff_mth1_cap_life_insurance_decreasing_cap    0\n",
       "diff_mth2_cap_life_insurance_decreasing_cap    0\n",
       "Length: 77, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_s.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a0f5b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,   3120,  27730, 100000,   1180,   2480,   1610,   3970,\n",
       "        63000,  12550,  16960,  40000,   1110,  82350,   2890,  18720,\n",
       "        49580,  76450,  24790,   2810,  10000,  54540,   1730,    580,\n",
       "        62000,   3130,  27210,  52330,  12390,    810,  50000,  20700,\n",
       "         3010,   3500,  16410,  38790,   9300,   2900,  69570,   3720,\n",
       "       125000,   2030,  12240,  12500, 171050,   1800,    670,  25010,\n",
       "         5000,   2440,  22400,    250,   1430,  37180,    430,   4310,\n",
       "        25000,    460,   6200,   7640,  22500,   7080,    530, 140000,\n",
       "        27160,  11850,    620,  59490,   3360,  56890,   1240,  25510,\n",
       "       104000,   9000,   9080,  10310,  85430, 127880, 200000,  91100,\n",
       "        14230,  41980,  30230,     90,   9340,   4960,   2090,  20000,\n",
       "        71690,  47830,  43380,    960, 150000,    990,  16110,   5040,\n",
       "       220000,   8250,   3200,  19900,  10860,   3400,  49470,   3620,\n",
       "         1990,   3060,   1260,   2260,   8750,  14390,   7680,   2450,\n",
       "         4000,  15840,  37860,   4760,    590,   7440,    680,  32070,\n",
       "          490,   3140,  50840,  97500,   6210,  11620,   9920, 117000,\n",
       "        18690], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1['cap_life_insurance_fixed_cap'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc9b460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s = change(test1,test2,test3, to_bool, to_diff_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7038dc",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd313d",
   "metadata": {},
   "source": [
    "### Categorical vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecbba722",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_variables = ['homebanking_active', 'has_homebanking',\n",
    "       'has_insurance_21', 'has_insurance_23', 'has_life_insurance_fixed_cap',\n",
    "       'has_life_insurance_decreasing_cap', 'has_fire_car_other_insurance',\n",
    "       'has_personal_loan', 'has_mortgage_loan', 'has_current_account',\n",
    "       'has_pension_saving', 'has_savings_account',\n",
    "       'has_savings_account_starter', 'has_current_account_starter','visits_distinct_so', 'visits_distinct_so_areas', 'customer_gender',\n",
    "       'customer_self_employed','ch_homebanking_active',\n",
    "       'ch_has_homebanking', 'ch_has_insurance_21', 'ch_has_insurance_23',\n",
    "       'ch_has_life_insurance_fixed_cap',\n",
    "       'ch_has_life_insurance_decreasing_cap',\n",
    "       'ch_has_fire_car_other_insurance', 'ch_has_personal_loan',\n",
    "       'ch_has_mortgage_loan', 'ch_has_current_account',\n",
    "       'ch_has_pension_saving', 'ch_has_savings_account',\n",
    "       'ch_has_savings_account_starter', 'ch_has_current_account_starter','customer_children']\n",
    "for var in cat_variables:\n",
    "    train_s[var] = pd.Categorical(train_s[var]) \n",
    "    test_s[var] = pd.Categorical(test_s[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6a071c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(5,3)}) \n",
    "# fig, axes = plt.subplots(11, 3, figsize=(100, 60))\n",
    "\n",
    "# i = 0\n",
    "# j = 0\n",
    "# for variable in cat_variables:\n",
    "#     sns.histplot(ax=axes[i, j],data=train_s, x=variable, hue = \"target\" , multiple=\"stack\",hue_order = [0,1])\n",
    "#     j = j + 1\n",
    "#     if (j > 2):\n",
    "#         j = 0\n",
    "#         i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e5dfa1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(11, 3, figsize=(100, 60))\n",
    "\n",
    "# i = 0\n",
    "# j = 0\n",
    "# for variable in cat_variables:\n",
    "#     sns.histplot(ax=axes[i, j],data=train_s, x=variable, hue = \"target\" , multiple=\"fill\",hue_order = [0,1])\n",
    "#     j = j + 1\n",
    "#     if (j > 2):\n",
    "#         j = 0\n",
    "#         i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4a06823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(5,3)}) \n",
    "# fig, axes = plt.subplots(11, 3, figsize=(100, 60))\n",
    "\n",
    "# i = 0\n",
    "# j = 0\n",
    "# for variable in cat_variables:\n",
    "#     plot = sns.histplot(ax=axes[i, j],data=train_s, x=variable, hue = \"target\" , multiple=\"fill\",hue_order = [0,1])\n",
    "#     plot.set(ylim=(0, 0.1))\n",
    "#     j = j + 1\n",
    "#     if (j > 2):\n",
    "#         j = 0\n",
    "#         i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "155fbd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_explore = ['has_insurance_23','has_insurance_21','has_fire_car_other_insurance',\n",
    "                   'ch_has_insurance_21','ch_has_savings_account','ch_has_current_account',\n",
    "                   'ch_homebanking_active','has_pension_saving','has_life_insurance_fixed_cap',\n",
    "                   'customer_postal_code','has_current_account_starter','ch_has_current_account_starter',\n",
    "                   'has_savings_account_starter','visits_distinct_so_areas','ch_has_life_insurance_decreasing_cap',\n",
    "                   'ch_has_mortgage_loan','ch_has_savings_account_starter','ch_has_fire_car_other_insurance',\n",
    "                   'ch_has_insurance_23','visits_distinct_so','ch_has_homebanking','ch_has_personal_loan',\n",
    "                   'ch_has_pension_saving','ch_has_current_account_starter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0cb141e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cat = []\n",
    "for x in cat_variables:\n",
    "    if x not in vars_to_explore:\n",
    "        keep_cat += [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "704909ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency \n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1bd3a715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_insurance_23: Independent (fail to reject H0)\n",
      "has_insurance_21: Dependent (reject H0)\n",
      "has_fire_car_other_insurance: Dependent (reject H0)\n",
      "ch_has_insurance_21: Independent (fail to reject H0)\n",
      "ch_has_savings_account: Independent (fail to reject H0)\n",
      "ch_has_current_account: Independent (fail to reject H0)\n",
      "ch_homebanking_active: Independent (fail to reject H0)\n",
      "has_pension_saving: Independent (fail to reject H0)\n",
      "has_life_insurance_fixed_cap: Independent (fail to reject H0)\n",
      "customer_postal_code: Dependent (reject H0)\n",
      "has_current_account_starter: Dependent (reject H0)\n",
      "ch_has_current_account_starter: Independent (fail to reject H0)\n",
      "has_savings_account_starter: Dependent (reject H0)\n",
      "visits_distinct_so_areas: Dependent (reject H0)\n",
      "ch_has_life_insurance_decreasing_cap: Dependent (reject H0)\n",
      "ch_has_mortgage_loan: Independent (fail to reject H0)\n",
      "ch_has_savings_account_starter: Independent (fail to reject H0)\n",
      "ch_has_fire_car_other_insurance: Dependent (reject H0)\n",
      "ch_has_insurance_23: Independent (fail to reject H0)\n",
      "visits_distinct_so: Dependent (reject H0)\n",
      "ch_has_homebanking: Independent (fail to reject H0)\n",
      "ch_has_personal_loan: Independent (fail to reject H0)\n",
      "ch_has_pension_saving: Independent (fail to reject H0)\n",
      "ch_has_current_account_starter: Independent (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "remove_cat = []\n",
    "for x in vars_to_explore:\n",
    "    test = pd.crosstab(train_s['target'],train_s[x],margins = False)\n",
    "    stat, p, dof, expected = chi2_contingency(test)\n",
    "    critical = chi2.ppf(0.99, dof)\n",
    "    if abs(stat) >= critical:\n",
    "        keep_cat = keep_cat + [x]\n",
    "        print(x + ': Dependent (reject H0)')\n",
    "    else:\n",
    "        remove_cat = remove_cat + [x]\n",
    "        print(x + ': Independent (fail to reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae94f1bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['homebanking_active', 'has_homebanking', 'has_life_insurance_decreasing_cap', 'has_personal_loan', 'has_mortgage_loan', 'has_current_account', 'has_savings_account', 'customer_gender', 'customer_self_employed', 'ch_has_life_insurance_fixed_cap', 'customer_children', 'has_insurance_21', 'has_fire_car_other_insurance', 'customer_postal_code', 'has_current_account_starter', 'has_savings_account_starter', 'visits_distinct_so_areas', 'ch_has_life_insurance_decreasing_cap', 'ch_has_fire_car_other_insurance', 'visits_distinct_so']\n"
     ]
    }
   ],
   "source": [
    "print(keep_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff2d040",
   "metadata": {},
   "source": [
    "### Continious vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6319e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_vars = ['bal_insurance_21', 'bal_insurance_23','bal_personal_loan', \n",
    "'bal_mortgage_loan', 'bal_current_account',\n",
    "'bal_pension_saving', 'bal_savings_account',\n",
    "'bal_savings_account_starter', 'bal_current_account_starter',\n",
    "'cap_life_insurance_fixed_cap','cap_life_insurance_decreasing_cap',\n",
    "'diff_mth1_bal_insurance_21', 'diff_mth2_bal_insurance_21',\n",
    "'diff_mth1_bal_insurance_23', 'diff_mth2_bal_insurance_23',\n",
    "'diff_mth1_bal_personal_loan', 'diff_mth2_bal_personal_loan',\n",
    "'diff_mth1_bal_mortgage_loan', 'diff_mth2_bal_mortgage_loan',\n",
    "'diff_mth1_bal_current_account', 'diff_mth2_bal_current_account',\n",
    "'diff_mth1_bal_pension_saving', 'diff_mth2_bal_pension_saving',\n",
    "'diff_mth1_bal_savings_account', 'diff_mth2_bal_savings_account',\n",
    "'diff_mth1_bal_savings_account_starter',\n",
    "'diff_mth2_bal_savings_account_starter',\n",
    "'diff_mth1_bal_current_account_starter',\n",
    "'diff_mth2_bal_current_account_starter',\n",
    "'diff_mth1_cap_life_insurance_fixed_cap',\n",
    "'diff_mth2_cap_life_insurance_fixed_cap',\n",
    "'diff_mth1_cap_life_insurance_decreasing_cap',\n",
    "'diff_mth2_cap_life_insurance_decreasing_cap','Age','Year_since_all','Year_since_bank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04b85ede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(5,3)}) \n",
    "# fig, axes = plt.subplots(12, 3, figsize=(100, 60))\n",
    "\n",
    "# i = 0\n",
    "# j = 0\n",
    "# for variable in cont_vars:\n",
    "#     sns.histplot(ax=axes[i, j],data=train_s, x=variable, hue = \"target\" , multiple=\"stack\",hue_order = [0,1],\n",
    "#                 bins = 50)\n",
    "#     j = j + 1\n",
    "#     if (j > 2):\n",
    "#         j = 0\n",
    "#         i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1983116d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(5,3)}) \n",
    "# fig, axes = plt.subplots(12, 3, figsize=(100, 60))\n",
    "\n",
    "# i = 0\n",
    "# j = 0\n",
    "# for variable in cont_vars:\n",
    "#     plot = sns.histplot(ax=axes[i, j],data=train_s, x=variable, hue = \"target\" , multiple=\"fill\",hue_order = [0,1],\n",
    "#                         bins = 50)\n",
    "#     plot.set(ylim=(0, 0.06))\n",
    "#     j = j + 1\n",
    "#     if (j > 2):\n",
    "#         j = 0\n",
    "#         i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "743a0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cont = ['bal_savings_account','diff_mth2_bal_savings_account','bal_current_account',\n",
    "             'diff_mth1_bal_current_account','diff_mth1_bal_savings_account','diff_mth2_bal_current_account',\n",
    "             'Age','Year_since_all','Year_since_bank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "945377a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vars = keep_cat + keep_cont\n",
    "len(final_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82a49442",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = train_s[['target']+final_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce786236",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = test_s[final_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb0abe4",
   "metadata": {},
   "source": [
    "## Final training set missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12d54fe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>missing values</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>customer_children</td>\n",
       "      <td>22147</td>\n",
       "      <td>37.89634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             variable  missing values         %\n",
       "11  customer_children           22147  37.89634"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = train_final.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['variable', 'missing values']\n",
    "missing_df['%']=(missing_df['missing values'])/train_final.shape[0]*100\n",
    "missing_df = missing_df[missing_df['missing values'] >0].sort_values('%')\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "460ceac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>missing values</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>customer_children</td>\n",
       "      <td>9553</td>\n",
       "      <td>38.193667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             variable  missing values          %\n",
       "10  customer_children            9553  38.193667"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = test_final.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['variable', 'missing values']\n",
    "missing_df['%']=(missing_df['missing values'])/test_final.shape[0]*100\n",
    "missing_df = missing_df[missing_df['missing values'] >0].sort_values('%')\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3b63d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9324\\96049550.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_final['customer_children'] = train_final['customer_children'].astype(str).replace(rep)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9324\\96049550.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_final['customer_children'] = test_final['customer_children'].astype(str).replace(rep)\n"
     ]
    }
   ],
   "source": [
    "rep = {'onebaby':'yes','preschool':'yes', 'young':'yes','adolescent':'yes','grownup':'yes','mature':'yes',\n",
    "      np.nan:'missing','nan':'yes'}\n",
    "train_final['customer_children'] = train_final['customer_children'].astype(str).replace(rep)\n",
    "test_final['customer_children'] = test_final['customer_children'].astype(str).replace(rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c7036085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>missing values</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [variable, missing values, %]\n",
       "Index: []"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = test_final.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['variable', 'missing values']\n",
    "missing_df['%']=(missing_df['missing values'])/test_final.shape[0]*100\n",
    "missing_df = missing_df[missing_df['missing values'] >0].sort_values('%')\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c3d8477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the old missing values that shouldn't be there have been fixed\n",
    "# train_final = train_final.dropna()\n",
    "# test_final = test_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb800f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1913"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_df['target'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "80988fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the initial data set, we lost 6% churners after cleaning the data set. We will move on to the modeling step.\n"
     ]
    }
   ],
   "source": [
    "print(\"From the initial data set, we lost \" + str(round((copy_df['target'].sum()-train_final['target'].sum())/copy_df['target'].sum() *100)) +\"%\" + \" churners after cleaning the data set. We will move on to the modeling step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d7284c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## PCA - not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29185b9f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Dimension reductioin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cca8a5a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #check if df is factorable \n",
    "# train_fa = train_s.drop(['client_id','target'],axis=1)\n",
    "# chi_square_value,p_value=calculate_bartlett_sphericity(train_fa)\n",
    "# chi_square_value, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c749be5e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# _,kmo_model=calculate_kmo(train_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "822b02aa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fa = FactorAnalyzer(n_factors=30,rotation=None )\n",
    "# fa.fit(train_fa )\n",
    "# # Check Eigenvalues\n",
    "# ev, v = fa.get_eigenvalues()\n",
    "# ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "58a18dd4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Create scree plot\n",
    "# plt.scatter(range(1,train_fa.shape[1]+1),ev)\n",
    "# plt.plot(range(1,train_fa.shape[1]+1),ev)\n",
    "# plt.title('Scree Plot')\n",
    "# plt.xlabel('Factors')\n",
    "# plt.ylabel('Eigenvalue')\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dee0ee65",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#  #Create factor analysis object and perform factor analysis\n",
    "# fa = FactorAnalyzer(20, rotation=\"varimax\")\n",
    "# fa.fit(train_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0bc2790a",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(fa.loadings_, index=train_fa.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "904e032b",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check variance explained \n",
    "# pd.DataFrame(fa.get_factor_variance(), index=['SS Loadings','Proportion Var','Cumulative Var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0d1dfd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9975ef02",
   "metadata": {},
   "source": [
    "## Prepare training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2fc154c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'homebanking_active', 'has_homebanking',\n",
       "       'has_life_insurance_decreasing_cap', 'has_personal_loan',\n",
       "       'has_mortgage_loan', 'has_current_account', 'has_savings_account',\n",
       "       'customer_gender', 'customer_self_employed',\n",
       "       'ch_has_life_insurance_fixed_cap', 'customer_children',\n",
       "       'has_insurance_21', 'has_fire_car_other_insurance',\n",
       "       'customer_postal_code', 'has_current_account_starter',\n",
       "       'has_savings_account_starter', 'visits_distinct_so_areas',\n",
       "       'ch_has_life_insurance_decreasing_cap',\n",
       "       'ch_has_fire_car_other_insurance', 'visits_distinct_so',\n",
       "       'bal_savings_account', 'diff_mth2_bal_savings_account',\n",
       "       'bal_current_account', 'diff_mth1_bal_current_account',\n",
       "       'diff_mth1_bal_savings_account', 'diff_mth2_bal_current_account', 'Age',\n",
       "       'Year_since_all', 'Year_since_bank'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "80d27aac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create matrix with interation terms\n",
    "y = train_final.iloc[:,0]\n",
    "X = pd.get_dummies(train_final,drop_first=True).iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aa20af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final = pd.get_dummies(test_final, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b40cd6d",
   "metadata": {},
   "source": [
    "## Prepare testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03339f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d3971",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fed62d",
   "metadata": {},
   "source": [
    "## Selecting best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2af950af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score,f1_score, ConfusionMatrixDisplay,precision_score,recall_score,f1_score,classification_report,roc_curve,plot_roc_curve,auc,precision_recall_curve,plot_precision_recall_curve,average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3c63368",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=4,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a6f7dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers to use\n",
    "models = []\n",
    "models.append(['KNeigbors',KNeighborsClassifier()])\n",
    "models.append(['RandomForest',RandomForestClassifier(random_state=4)])\n",
    "models.append(['AdaBoostClassifier',AdaBoostClassifier(random_state=4)])\n",
    "models.append(['LogisticsRegression', LogisticRegression(solver = 'saga',max_iter = 1000)])\n",
    "models.append(['GradientBoost',GradientBoostingClassifier(learning_rate=0.1,random_state=4)])\n",
    "models.append(['XGBClassifier',xgb.XGBClassifier(random_state=4, n_jobs =4,use_label_encoder=False)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678bf6f4",
   "metadata": {},
   "source": [
    "We first fits the models without adding or changing any parameters using cross-validation technique.\\\n",
    "Our future goal is to have a robust model to work on unseen data. We are more interested in the precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8ae7f3e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeigbors :\n",
      "[[16991     4]\n",
      " [  529     9]]\n",
      "AUC: 0.957\n",
      "10-CV AUC: 0.544\n",
      "10-CV Accuracy Standard Deviation: 0.013\n",
      "RandomForest :\n",
      "[[16995     0]\n",
      " [    0   538]]\n",
      "AUC: 1.000\n",
      "10-CV AUC: 0.701\n",
      "10-CV Accuracy Standard Deviation: 0.021\n",
      "AdaBoostClassifier :\n",
      "[[16994     1]\n",
      " [  537     1]]\n",
      "AUC: 0.770\n",
      "10-CV AUC: 0.738\n",
      "10-CV Accuracy Standard Deviation: 0.013\n",
      "LogisticsRegression :\n",
      "[[16995     0]\n",
      " [  538     0]]\n",
      "AUC: 0.665\n",
      "10-CV AUC: 0.652\n",
      "10-CV Accuracy Standard Deviation: 0.019\n",
      "GradientBoost :\n",
      "[[16995     0]\n",
      " [  532     6]]\n",
      "AUC: 0.789\n",
      "10-CV AUC: 0.750\n",
      "10-CV Accuracy Standard Deviation: 0.017\n",
      "[02:56:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[02:56:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier :\n",
      "[[16995     0]\n",
      " [  412   126]]\n",
      "AUC: 0.950\n",
      "10-CV AUC: 0.691\n",
      "10-CV Accuracy Standard Deviation: 0.019\n"
     ]
    }
   ],
   "source": [
    "lst_1 = []\n",
    "for m in range(len(models)):\n",
    "    lst_2 = []\n",
    "    model = models[m][1]\n",
    "    model.fit(X,y)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:,1]\n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    AUC_cv = cross_val_score(estimator= model, X = X_train,y = y_train, cv=5,scoring = 'roc_auc')\n",
    "    \n",
    "    recall =  tp/(tp + fn) # more imp\n",
    "    specificity = tn/(tn+fp) # most imp\n",
    "    precision = tp/(tp+fp) # least imp\n",
    "    accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\n",
    "    AUC = auc(false_positive_rate, true_positive_rate)\n",
    "    \n",
    "    print(models[m][0],':')\n",
    "    print(cm)\n",
    "    print('AUC: {:.3f}'.format(AUC))\n",
    "    print('10-CV AUC: {:.3f}'.format(AUC_cv.mean())) \n",
    "    print('10-CV Accuracy Standard Deviation: {:.3f}'.format(AUC_cv.std())) \n",
    "    \n",
    "    lst_2.append(models[m][0])\n",
    "    lst_2.append(AUC)\n",
    "    lst_2.append(AUC_cv.mean())\n",
    "    lst_2.append(AUC_cv.std())\n",
    "    lst_1.append(lst_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9592bb7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC</th>\n",
       "      <th>10-CV AUC</th>\n",
       "      <th>10-CV Acc std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeigbors</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticsRegression</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model    AUC  10-CV AUC  10-CV Acc std\n",
       "0         RandomForest  1.000      0.701          0.021\n",
       "1            KNeigbors  0.957      0.544          0.013\n",
       "2        XGBClassifier  0.950      0.691          0.019\n",
       "3        GradientBoost  0.789      0.750          0.017\n",
       "4   AdaBoostClassifier  0.770      0.738          0.013\n",
       "5  LogisticsRegression  0.665      0.652          0.019"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(lst_1,columns=['Model','AUC','10-CV AUC','10-CV Acc std'])\n",
    "\n",
    "df2.sort_values(by=['AUC'],inplace=True,ascending=False)\n",
    "df2.reset_index(drop = True).round(decimals = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e60b746",
   "metadata": {},
   "source": [
    "From the above matrix and the table shown above, XGBClassifier works best in catching True & False positives. However, the models accuracy drops by 30% after cross validation. Additionally, the low AUC score after 10 folds cv shows that we are overfitting the data. \\\n",
    "The main reason that we are having this issue is because we have an imbalanced target variable. Therefore we will try the following techniques to improve the model:\n",
    "- Over sampling churned targets\n",
    "- Smart sampling churned targets\n",
    "- Adding misclassification costs (We will start with the inverse class distribution)\n",
    "\n",
    "Our aim forward is to improve True positives/False positives ratio .\\\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33a2816",
   "metadata": {},
   "source": [
    "# Wissam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298184a2",
   "metadata": {},
   "source": [
    "##  Sampling techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade1e88a",
   "metadata": {},
   "source": [
    "### Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "#models.append(['AdaBoostClassifier',AdaBoostClassifier(random_state=4)])\n",
    "\n",
    "# models.append(['GradientBoost',GradientBoostingClassifier(learning_rate=0.1,random_state=4)])\n",
    "models.append(['XGBClassifier',xgb.XGBClassifier(eval_metric='logloss',random_state=4, n_jobs =4,use_label_encoder=False,scale_pos_weight=32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd893fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=4)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_1 = []\n",
    "for m in range(len(models)):\n",
    "    lst_2 = []\n",
    "    model = models[m][1]\n",
    "    model.fit(X,y)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:,1]\n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    tn, fp, fn, tp= confusion_matrix(y_test, predicted,labels=[0,1]).ravel()\n",
    "    AUC_cv = cross_val_score(estimator= model, X = X_resampled,y = y_resampled, cv=5,scoring = 'roc_auc')\n",
    "    \n",
    "    recall =  tp/(tp + fn) # more imp\n",
    "    specificity = tn/(tn+fp) # most imp\n",
    "    precision = tp/(tp+fp) # least imp\n",
    "    accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\n",
    "    AUC = auc(false_positive_rate, true_positive_rate)\n",
    "    \n",
    "    print(models[m][0],':')\n",
    "    print(cm)\n",
    "    print('AUC: {:.3f}'.format(AUC))\n",
    "    print('10-CV AUC: {:.3f}'.format(AUC_cv.mean())) \n",
    "    print('10-CV Accuracy Standard Deviation: {:.3f}'.format(AUC_cv.std())) \n",
    "    \n",
    "    lst_2.append(models[m][0])\n",
    "    lst_2.append(AUC)\n",
    "    lst_2.append(AUC_cv.mean())\n",
    "    lst_2.append(AUC_cv.std())\n",
    "    lst_1.append(lst_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb37fbd",
   "metadata": {},
   "source": [
    "### Smart Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af1c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=4,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9531a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_index = list(range(11,38))\n",
    "sm = SMOTENC(categorical_features=cat_col_index, random_state=4, sampling_strategy=0.8)\n",
    "X_trainres, y_trainres = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7372df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainres.sum()/len(y_trainres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a44121",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.sum()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c4fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_1 = []\n",
    "for m in range(len(models)):\n",
    "    lst_2 = []\n",
    "    model = models[m][1]\n",
    "    model.fit(X,y)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:,1]\n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    AUC_cv = cross_val_score(estimator= model, X = X_trainres,y = y_trainres, cv=5,scoring = 'roc_auc')\n",
    "    \n",
    "    recall =  tp/(tp + fn) # more imp\n",
    "    specificity = tn/(tn+fp) # most imp\n",
    "    precision = tp/(tp+fp) # least imp\n",
    "    accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_prob)\n",
    "    AUC = auc(false_positive_rate, true_positive_rate)\n",
    "    \n",
    "    print(models[m][0],':')\n",
    "    print(cm)\n",
    "    print('AUC: {:.3f}'.format(AUC))\n",
    "    print('10-CV AUC: {:.3f}'.format(AUC_cv.mean())) \n",
    "    print('10-CV Accuracy Standard Deviation: {:.3f}'.format(AUC_cv.std())) \n",
    "    \n",
    "    lst_2.append(models[m][0])\n",
    "    lst_2.append(AUC)\n",
    "    lst_2.append(AUC_cv.mean())\n",
    "    lst_2.append(AUC_cv.std())\n",
    "    lst_1.append(lst_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(lst_1,columns=['Model','AUC','10-CV AUC','10-CV Acc std'])\n",
    "\n",
    "df2.sort_values(by=['AUC'],inplace=True,ascending=False)\n",
    "df2.reset_index(drop = True).round(decimals = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0c58e5",
   "metadata": {},
   "source": [
    "In summary, the models are performing better on the test set after sampling the data. So far, XGBClassifier is the best candidate to model our data.\\\n",
    "\n",
    "Note: Over-sampling and smart sampling gave the same results. Hence, we will move forward with over-sampling for its quick computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca786f9",
   "metadata": {},
   "source": [
    "# Tune Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c2fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(15,150,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,stratify=y)\n",
    "    model_GNB = xgb.XGBClassifier(eval_metric ='logloss',random_state=4, n_jobs =4, scale_pos_weight=x )\n",
    "    model_GNB.fit(X_train,y_train)\n",
    "    predicted = model_GNB.predict(X_test)\n",
    "    cm = confusion_matrix(y_test,predicted)\n",
    "    tn, fp, fn, tp= confusion_matrix(y_test, predicted,labels=[0,1]).ravel()\n",
    "    print(x, tp, fp, tp/fp)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf34576",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GNB = xgb.XGBClassifier(random_state=4, n_jobs =4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa306f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GNB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model_GNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3353689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe3b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GNB.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "216px",
    "width": "363px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "281.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
